{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dcadfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research import researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d74df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cca59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb2458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf690ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " array(['setosa', 'versicolor', 'virginica'], dtype='<U10'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names'] , data['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca05719",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "data = {\n",
    "    \"X_train\": X_train,\n",
    "    \"X_test\": X_test,\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651181be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class regression_model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \"\"\"\n",
    "        input_size: number of input features\n",
    "        output_size: number of classes\n",
    "        hidden_size: number of neurons in hidden layers\n",
    "        num_hidden_layers: number of hidden layers\n",
    "        dropout: dropout probability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []  # flatten input\n",
    "\n",
    "        # 1 layer\n",
    "        layers.append(nn.Linear(input_size, output_size))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        # Combine all layers into a sequential module\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34e750a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression_model(input_size=4, output_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e146b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"hyperparameter\": {\n",
    "        \"range\": {\n",
    "            \"batch_size\": [16, 32, 16],\n",
    "            \"learning_rate\": [0.001, 0.01, 0.009],\n",
    "        },\n",
    "        \"choice\": {\n",
    "\n",
    "        },\n",
    "        \"fixed\": {\n",
    "            \"epochs\": 50,\n",
    "            \"loss_fn\": nn.CrossEntropyLoss(),\n",
    "            \"optimizer\": torch.optim.Adam\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a8581f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(self):\n",
    "\n",
    "    model = self.model\n",
    "    loss_fn = self.loss_fn\n",
    "    lr = self.learning_rate\n",
    "    optimizer = self.optimizer(model.parameters(), lr=lr)\n",
    "    epochs = self.epochs\n",
    "    batch_size = self.batch_size\n",
    "    accuracy_fn = self.accuracy_fn\n",
    "    info = None\n",
    "\n",
    "    data = self.data\n",
    "\n",
    "    X_train = torch.tensor(data.X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(data.y_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(data.X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(data.y_test, dtype=torch.float32)\n",
    "\n",
    "    total_loss_train = 0\n",
    "    total_loss_test = 0\n",
    "    total_acc_train = 0\n",
    "    total_acc_test = 0\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        total_loss_train = 0\n",
    "        for bt , (X_train, y_train) in enumerate(train_loader):\n",
    "\n",
    "            y_train_logit = model(X_train)\n",
    "            y_train_pred = torch.round(y_train_logit)\n",
    "\n",
    "            loss = loss_fn(y_train_logit, y_train.long())\n",
    "            total_loss_train += loss.item() * X_train.size(0)\n",
    "            total_acc_train += accuracy_fn(y_train, y_train_pred) * X_train.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        total_loss_test = 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            for bt , (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "                y_test_logit = model(X_test)\n",
    "                y_test_pred = torch.round(y_test_logit)\n",
    "\n",
    "                loss_test = loss_fn(y_test_logit, y_test.long())\n",
    "                total_loss_test += loss_test.item() * X_test.size(0)\n",
    "                total_acc_test += accuracy_fn(y_test, y_test_pred) * X_test.size(0)\n",
    "\n",
    "        avg_loss_train = total_loss_train / len(train_loader.dataset)\n",
    "        avg_loss_test = total_loss_test / len(test_loader.dataset)\n",
    "        avg_acc_train = total_acc_train / len(train_loader.dataset)\n",
    "        avg_acc_test = total_acc_test / len(test_loader.dataset)\n",
    "\n",
    "        if epoch % (epochs/10) == 0:\n",
    "            print(f\"Epoch {epoch+1} | Train Loss: {avg_loss_train:.4f} | Test Loss: {avg_loss_test:.4f} | Train Acc: {avg_acc_train:.2f} | Test Acc: {avg_acc_test:.2f}\")\n",
    "\n",
    "        info = {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"learning_rate\": lr\n",
    "        }\n",
    "        self.bestModel(avg_loss_train, avg_loss_test, model, epoch, info)\n",
    "\n",
    "    return {\n",
    "        \"avg_loss_train\": avg_loss_train,\n",
    "        \"avg_loss_test\": avg_loss_test,\n",
    "        \"model\": model,\n",
    "        \"epoch\": epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5392cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter Researcher initialized.\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.001\n",
      "  epochs: 50\n",
      "  loss_fn: CrossEntropyLoss()\n",
      "  optimizer: <class 'torch.optim.adam.Adam'>\n"
     ]
    }
   ],
   "source": [
    "argument = {\n",
    "    \"data\": data,\n",
    "    \"model\": model,\n",
    "    \"train_loop\": train_loop,\n",
    "    \"config\": config,\n",
    "    \"grid_search\": True,\n",
    "    \"research_type\": 1\n",
    "}\n",
    "model_researcher = researcher(**argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c02e6176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter research... with train type: <bound method researcher.startGridSearchHyperparameter of <research.researcher object at 0x00000205B08EB550>>\n",
      "0\n",
      "1\n",
      "2\n",
      "Training with hyperparameters: <research.obj object at 0x000002058FF0C9D0>\n",
      "Prepared training data and hyperparameters for training loop.\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.001\n",
      "  epochs: 50\n",
      "  loss_fn: CrossEntropyLoss()\n",
      "  optimizer: <class 'torch.optim.adam.Adam'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "researcher.accuracy_fn() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel_researcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartResearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Research_hyperparameter\\research.py:166\u001b[39m, in \u001b[36mresearcher.startResearch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_case == \u001b[33m\"\u001b[39m\u001b[33mhyperparameter\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mprint\u001b[39m( \u001b[33m\"\u001b[39m\u001b[33mStarting hyperparameter research... with train type:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.train_type )\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_case == \u001b[33m\"\u001b[39m\u001b[33mhyperparameterAndConfigModel\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mprint\u001b[39m( \u001b[33m\"\u001b[39m\u001b[33mStarting hyperparameter and config model research... with train type:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.model_train_type )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Research_hyperparameter\\research.py:264\u001b[39m, in \u001b[36mresearcher.startGridSearchHyperparameter\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    262\u001b[39m         grid_search_hyperparameter_range(index + \u001b[32m1\u001b[39m)\n\u001b[32m    263\u001b[39m         value += step\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m \u001b[43mgrid_search_hyperparameter_range\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Research_hyperparameter\\research.py:262\u001b[39m, in \u001b[36mresearcher.startGridSearchHyperparameter.<locals>.grid_search_hyperparameter_range\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m value <= high:\n\u001b[32m    261\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.now.hyperparameter, key, value)\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[43mgrid_search_hyperparameter_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m     value += step\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Research_hyperparameter\\research.py:262\u001b[39m, in \u001b[36mresearcher.startGridSearchHyperparameter.<locals>.grid_search_hyperparameter_range\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m value <= high:\n\u001b[32m    261\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.now.hyperparameter, key, value)\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[43mgrid_search_hyperparameter_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m     value += step\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Research_hyperparameter\\research.py:254\u001b[39m, in \u001b[36mresearcher.startGridSearchHyperparameter.<locals>.grid_search_hyperparameter_range\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mprint\u001b[39m(index)\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index == \u001b[38;5;28mlen\u001b[39m(hyper_keys_range):\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[43mgrid_search_hyperparameter_choice\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    257\u001b[39m key = hyper_keys_range[index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Research_hyperparameter\\research.py:242\u001b[39m, in \u001b[36mresearcher.startGridSearchHyperparameter.<locals>.grid_search_hyperparameter_choice\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index == \u001b[38;5;28mlen\u001b[39m(hyper_keys_choice):\n\u001b[32m    241\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining with hyperparameters:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.now.hyperparameter)\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_data_and_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28mself\u001b[39m.bestModel()\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Desktop\\Research_hyperparameter\\research.py:141\u001b[39m, in \u001b[36mresearcher.prepare_data_and_train_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28mself\u001b[39m.train_data.bestModel = \u001b[38;5;28mself\u001b[39m.bestModel\n\u001b[32m    139\u001b[39m \u001b[38;5;28mself\u001b[39m.train_data.accuracy_fn = \u001b[38;5;28mself\u001b[39m.accuracy_fn\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     38\u001b[39m loss = loss_fn(y_train_logit, y_train.long())\n\u001b[32m     39\u001b[39m total_loss_train += loss.item() * X_train.size(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m total_acc_train += \u001b[43maccuracy_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pred\u001b[49m\u001b[43m)\u001b[49m * X_train.size(\u001b[32m0\u001b[39m)\n\u001b[32m     42\u001b[39m optimizer.zero_grad()\n\u001b[32m     44\u001b[39m loss.backward()\n",
      "\u001b[31mTypeError\u001b[39m: researcher.accuracy_fn() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "model_researcher.startResearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabd490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_researcher.print_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
